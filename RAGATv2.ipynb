{"cells":[{"cell_type":"markdown","metadata":{"id":"a9vTDPByuT7L"},"source":["# RAGATv2\n","This notebook is an improved version of the [RAGAT: Relation Aware Graph Attention Network for Knowledge Graph Completion](https://ieeexplore.ieee.org/document/9340326).   \n","The main focus of this improvement is to reduce the number of parameters in the model and also to fix the static attention problem.   \n","The code is based on the implementation of the RAGAT model which can be found [here](https://github.com/liuxiyang641/RAGAT)."]},{"cell_type":"markdown","metadata":{"id":"yHYutNYA6he1"},"source":["## Requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-30T18:59:38.196576Z","iopub.status.busy":"2023-09-30T18:59:38.196185Z","iopub.status.idle":"2023-09-30T18:59:39.300187Z","shell.execute_reply":"2023-09-30T18:59:39.299065Z","shell.execute_reply.started":"2023-09-30T18:59:38.196551Z"},"id":"n0dA4hEfvwXa","outputId":"acdfffc1-30fc-435e-bd2e-0924530761ee","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Sep 30 18:59:39 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-30T18:59:51.272644Z","iopub.status.busy":"2023-09-30T18:59:51.272071Z","iopub.status.idle":"2023-09-30T18:59:54.785920Z","shell.execute_reply":"2023-09-30T18:59:54.784912Z","shell.execute_reply.started":"2023-09-30T18:59:51.272602Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.0\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-08-29T11:30:55.263217Z","iopub.status.busy":"2023-08-29T11:30:55.262536Z","iopub.status.idle":"2023-08-29T11:30:56.304006Z","shell.execute_reply":"2023-08-29T11:30:56.302571Z","shell.execute_reply.started":"2023-08-29T11:30:55.263162Z"},"id":"ZxT9-0xJvvvr","outputId":"c0de4880-a4c7-4315-b29d-925c490f0c03","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.12\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-08-29T11:30:56.308614Z","iopub.status.busy":"2023-08-29T11:30:56.307394Z","iopub.status.idle":"2023-08-29T11:30:57.584938Z","shell.execute_reply":"2023-08-29T11:30:57.583450Z","shell.execute_reply.started":"2023-08-29T11:30:56.308572Z"},"id":"jhCSr_ye6ECo","outputId":"4c2ceed1-862e-468a-abd4-819b919230cb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:30:57.593786Z","iopub.status.busy":"2023-08-29T11:30:57.587057Z","iopub.status.idle":"2023-08-29T11:30:57.599104Z","shell.execute_reply":"2023-08-29T11:30:57.597835Z","shell.execute_reply.started":"2023-08-29T11:30:57.593743Z"},"id":"ryr_HR1SKC_I","trusted":true},"outputs":[],"source":["# !pip install torch==1.5.1 torchvision==0.6.1"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-08-29T11:30:57.603647Z","iopub.status.busy":"2023-08-29T11:30:57.602482Z","iopub.status.idle":"2023-08-29T11:31:14.756531Z","shell.execute_reply":"2023-08-29T11:31:14.755150Z","shell.execute_reply.started":"2023-08-29T11:30:57.603607Z"},"id":"nI9BCIyhzSZL","outputId":"9047d38f-7c51-4e73-f530-466c2d3e69be","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Installing collected packages: ordered-set\n","Successfully installed ordered-set-4.1.0\n"]}],"source":["!pip install ordered-set"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:14.762820Z","iopub.status.busy":"2023-08-29T11:31:14.762412Z","iopub.status.idle":"2023-08-29T11:31:18.540717Z","shell.execute_reply":"2023-08-29T11:31:18.539705Z","shell.execute_reply.started":"2023-08-29T11:31:14.762783Z"},"id":"URMIA6Fw5fTW","trusted":true},"outputs":[],"source":["import traceback, sys, os, random, pdb, json, uuid, time, argparse, inspect\n","\n","import numpy as np\n","from pprint import pprint\n","import logging, logging.config\n","from collections import defaultdict as ddict\n","from ordered_set import OrderedSet\n","\n","# PyTorch related imports\n","import torch\n","from torch.nn import functional as F\n","from torch.nn.init import xavier_normal_\n","from torch.utils.data import DataLoader\n","from torch.nn import Parameter\n","from torch.utils.data import Dataset"]},{"cell_type":"markdown","metadata":{"id":"C2Idd_MwW7_b"},"source":["## Dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-08-29T11:31:18.543185Z","iopub.status.busy":"2023-08-29T11:31:18.542302Z","iopub.status.idle":"2023-08-29T11:31:21.161748Z","shell.execute_reply":"2023-08-29T11:31:21.160411Z","shell.execute_reply.started":"2023-08-29T11:31:18.543143Z"},"id":"hmhZpgavW9LY","outputId":"063e70da-2b39-409d-fdba-3cd8b1376aca","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'RAGAT'...\n","remote: Enumerating objects: 63, done.\u001b[K\n","remote: Counting objects: 100% (25/25), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 63 (delta 17), reused 17 (delta 17), pack-reused 38\u001b[K\n","Receiving objects: 100% (63/63), 6.85 MiB | 13.72 MiB/s, done.\n","Resolving deltas: 100% (23/23), done.\n"]}],"source":["!git clone https://github.com/liuxiyang641/RAGAT.git"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:21.164409Z","iopub.status.busy":"2023-08-29T11:31:21.163764Z","iopub.status.idle":"2023-08-29T11:31:22.251006Z","shell.execute_reply":"2023-08-29T11:31:22.249487Z","shell.execute_reply.started":"2023-08-29T11:31:21.164361Z"},"id":"E_weNtGeXV4c","trusted":true},"outputs":[],"source":["!mv RAGAT/data ."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:22.259451Z","iopub.status.busy":"2023-08-29T11:31:22.256833Z","iopub.status.idle":"2023-08-29T11:31:23.543933Z","shell.execute_reply":"2023-08-29T11:31:23.542415Z","shell.execute_reply.started":"2023-08-29T11:31:22.259410Z"},"id":"swLvhNiWBn10","trusted":true},"outputs":[],"source":["!mv RAGAT/config ."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:23.556034Z","iopub.status.busy":"2023-08-29T11:31:23.553489Z","iopub.status.idle":"2023-08-29T11:31:24.744719Z","shell.execute_reply":"2023-08-29T11:31:24.743075Z","shell.execute_reply.started":"2023-08-29T11:31:23.555994Z"},"id":"tqeX0chmXklg","trusted":true},"outputs":[],"source":["!rm -r RAGAT"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:24.752104Z","iopub.status.busy":"2023-08-29T11:31:24.750751Z","iopub.status.idle":"2023-08-29T11:31:27.068326Z","shell.execute_reply":"2023-08-29T11:31:27.066800Z","shell.execute_reply.started":"2023-08-29T11:31:24.752056Z"},"trusted":true},"outputs":[],"source":["!mkdir checkpoints\n","!mkdir log"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.071063Z","iopub.status.busy":"2023-08-29T11:31:27.070620Z","iopub.status.idle":"2023-08-29T11:31:27.077519Z","shell.execute_reply":"2023-08-29T11:31:27.076366Z","shell.execute_reply.started":"2023-08-29T11:31:27.071030Z"},"trusted":true},"outputs":[],"source":["log_dir = './log/'"]},{"cell_type":"markdown","metadata":{"id":"DpPOr3rxWYI4"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.080459Z","iopub.status.busy":"2023-08-29T11:31:27.079570Z","iopub.status.idle":"2023-08-29T11:31:27.104386Z","shell.execute_reply":"2023-08-29T11:31:27.103252Z","shell.execute_reply.started":"2023-08-29T11:31:27.080420Z"},"id":"1AJwl89aWZ41","trusted":true},"outputs":[],"source":["class TrainDataset(Dataset):\n","    \"\"\"\n","    Training Dataset class.\n","    Parameters\n","    ----------\n","    triples:\tThe triples used for training the model\n","    params:\t\tParameters for the experiments\n","    Returns\n","    -------\n","    A training Dataset class instance used by DataLoader\n","    \"\"\"\n","\n","    def __init__(self, triples, params):\n","        self.triples = triples\n","        self.p = params\n","        self.entities = np.arange(self.p.num_ent, dtype=np.int32)\n","\n","    def __len__(self):\n","        return len(self.triples)\n","\n","    def __getitem__(self, idx):\n","        ele = self.triples[idx]\n","        triple, label, sub_samp = torch.LongTensor(ele['triple']), np.int32(ele['label']), np.float32(ele['sub_samp'])\n","        trp_label = self.get_label(label)\n","\n","        if self.p.lbl_smooth != 0.0:\n","            trp_label = (1.0 - self.p.lbl_smooth) * trp_label + (1.0 / self.p.num_ent)\n","\n","        if self.p.strategy == 'one_to_n':\n","            return triple, trp_label, None, None\n","\n","        elif self.p.strategy == 'one_to_x':\n","            sub_samp = torch.FloatTensor([sub_samp])\n","            neg_ent = torch.LongTensor(self.get_neg_ent(triple, label))\n","            return triple, trp_label, neg_ent, sub_samp\n","        else:\n","            raise NotImplementedError\n","\n","        # return triple, trp_label, None, None\n","\n","    @staticmethod\n","    def collate_fn(data):\n","        triple = torch.stack([_[0] for _ in data], dim=0)\n","        trp_label = torch.stack([_[1] for _ in data], dim=0)\n","        # triple: (batch-size) * 3(sub, rel, -1) trp_label (batch-size) * num entity\n","        # return triple, trp_label\n","        if not data[0][2] is None:  # one_to_x\n","            neg_ent = torch.stack([_[2] for _ in data], dim=0)\n","            sub_samp = torch.cat([_[3] for _ in data], dim=0)\n","            return triple, trp_label, neg_ent, sub_samp\n","        else:\n","            return triple, trp_label\n","\n","    # def get_neg_ent(self, triple, label):\n","    #     def get(triple, label):\n","    #         pos_obj = label\n","    #         mask = np.ones([self.p.num_ent], dtype=np.bool)\n","    #         mask[label] = 0\n","    #         neg_ent = np.int32(\n","    #             np.random.choice(self.entities[mask], self.p.neg_num - len(label), replace=False)).reshape([-1])\n","    #         neg_ent = np.concatenate((pos_obj.reshape([-1]), neg_ent))\n","    #\n","    #         return neg_ent\n","    #\n","    #     neg_ent = get(triple, label)\n","    #     return neg_ent\n","    def get_neg_ent(self, triple, label):\n","        def get(triple, label):\n","            if self.p.strategy == 'one_to_x':\n","                pos_obj = triple[2]\n","                mask = np.ones([self.p.num_ent], dtype=np.bool)\n","                mask[label] = 0\n","                neg_ent = np.int32(np.random.choice(self.entities[mask], self.p.neg_num, replace=False)).reshape([-1])\n","                neg_ent = np.concatenate((pos_obj.reshape([-1]), neg_ent))\n","            else:\n","                pos_obj = label\n","                mask = np.ones([self.p.num_ent], dtype=np.bool)\n","                mask[label] = 0\n","                neg_ent = np.int32(\n","                    np.random.choice(self.entities[mask], self.p.neg_num - len(label), replace=False)).reshape([-1])\n","                neg_ent = np.concatenate((pos_obj.reshape([-1]), neg_ent))\n","\n","                if len(neg_ent) > self.p.neg_num:\n","                    import pdb;\n","                    pdb.set_trace()\n","\n","            return neg_ent\n","\n","        neg_ent = get(triple, label)\n","        return neg_ent\n","\n","    def get_label(self, label):\n","        # y = np.zeros([self.p.num_ent], dtype=np.float32)\n","        # for e2 in label: y[e2] = 1.0\n","        # return torch.FloatTensor(y)\n","        if self.p.strategy == 'one_to_n':\n","            y = np.zeros([self.p.num_ent], dtype=np.float32)\n","            for e2 in label: y[e2] = 1.0\n","        elif self.p.strategy == 'one_to_x':\n","            y = [1] + [0] * self.p.neg_num\n","        else:\n","            raise NotImplementedError\n","        return torch.FloatTensor(y)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.106656Z","iopub.status.busy":"2023-08-29T11:31:27.105869Z","iopub.status.idle":"2023-08-29T11:31:27.120216Z","shell.execute_reply":"2023-08-29T11:31:27.119235Z","shell.execute_reply.started":"2023-08-29T11:31:27.106616Z"},"id":"8Ymy2XLAWgbR","trusted":true},"outputs":[],"source":["class TestDataset(Dataset):\n","    \"\"\"\n","    Evaluation Dataset class.\n","    Parameters\n","    ----------\n","    triples:\tThe triples used for evaluating the model\n","    params:\t\tParameters for the experiments\n","    Returns\n","    -------\n","    An evaluation Dataset class instance used by DataLoader for model evaluation\n","    \"\"\"\n","\n","    def __init__(self, triples, params):\n","        self.triples = triples\n","        self.p = params\n","\n","    def __len__(self):\n","        return len(self.triples)\n","\n","    def __getitem__(self, idx):\n","        ele = self.triples[idx]\n","        triple, label = torch.LongTensor(ele['triple']), np.int32(ele['label'])\n","        label = self.get_label(label)\n","\n","        return triple, label\n","\n","    @staticmethod\n","    def collate_fn(data):\n","        triple = torch.stack([_[0] for _ in data], dim=0)\n","        label = torch.stack([_[1] for _ in data], dim=0)\n","        return triple, label\n","\n","    def get_label(self, label):\n","        y = np.zeros([self.p.num_ent], dtype=np.float32)\n","        for e2 in label: y[e2] = 1.0\n","        return torch.FloatTensor(y)"]},{"cell_type":"markdown","metadata":{"id":"NnKkj0H56gB4"},"source":["## Helper"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.121780Z","iopub.status.busy":"2023-08-29T11:31:27.121379Z","iopub.status.idle":"2023-08-29T11:31:27.135260Z","shell.execute_reply":"2023-08-29T11:31:27.134379Z","shell.execute_reply.started":"2023-08-29T11:31:27.121746Z"},"trusted":true},"outputs":[],"source":["def pytorch_total_params(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    return total_params"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.139277Z","iopub.status.busy":"2023-08-29T11:31:27.138995Z","iopub.status.idle":"2023-08-29T11:31:27.146811Z","shell.execute_reply":"2023-08-29T11:31:27.145817Z","shell.execute_reply.started":"2023-08-29T11:31:27.139252Z"},"id":"AYQ5CBW66kB4","trusted":true},"outputs":[],"source":["def set_gpu(gpus):\n","    \"\"\"\n","    Sets the GPU to be used for the run\n","    Parameters\n","    ----------\n","    gpus:           List of GPUs to be used for the run\n","    Returns\n","    -------\n","    \"\"\"\n","    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.150736Z","iopub.status.busy":"2023-08-29T11:31:27.150417Z","iopub.status.idle":"2023-08-29T11:31:27.162138Z","shell.execute_reply":"2023-08-29T11:31:27.161146Z","shell.execute_reply.started":"2023-08-29T11:31:27.150705Z"},"id":"sG2H9ErY67dN","trusted":true},"outputs":[],"source":["def get_logger(name, log_dir, config_dir):\n","    \"\"\"\n","    Creates a logger object\n","    Parameters\n","    ----------\n","    name:           Name of the logger file\n","    log_dir:        Directory where logger file needs to be stored\n","    config_dir:     Directory from where log_config.json needs to be read\n","    Returns\n","    -------\n","    A logger object which writes to both file and stdout\n","    \"\"\"\n","    config_dict = json.load(open(config_dir + 'log_config.json'))\n","    config_dict['handlers']['file_handler']['filename'] = log_dir + name.replace('/', '-')\n","    logging.config.dictConfig(config_dict)\n","    logger = logging.getLogger(name)\n","\n","    std_out_format = '%(asctime)s - [%(levelname)s] - %(message)s'\n","    consoleHandler = logging.StreamHandler(sys.stdout)\n","    consoleHandler.setFormatter(logging.Formatter(std_out_format))\n","    logger.addHandler(consoleHandler)\n","\n","    return logger"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.166564Z","iopub.status.busy":"2023-08-29T11:31:27.165990Z","iopub.status.idle":"2023-08-29T11:31:27.178194Z","shell.execute_reply":"2023-08-29T11:31:27.177074Z","shell.execute_reply.started":"2023-08-29T11:31:27.166521Z"},"id":"1F9w6L416-65","trusted":true},"outputs":[],"source":["def get_combined_results(left_results, right_results):\n","    results = {}\n","    count = float(left_results['count'])\n","\n","    results['left_mr'] = round(left_results['mr'] / count, 5)\n","    results['left_mrr'] = round(left_results['mrr'] / count, 5)\n","    results['right_mr'] = round(right_results['mr'] / count, 5)\n","    results['right_mrr'] = round(right_results['mrr'] / count, 5)\n","    results['mr'] = round((left_results['mr'] + right_results['mr']) / (2 * count), 5)\n","    results['mrr'] = round((left_results['mrr'] + right_results['mrr']) / (2 * count), 5)\n","\n","    for k in range(10):\n","        results['left_hits@{}'.format(k + 1)] = round(left_results['hits@{}'.format(k + 1)] / count, 5)\n","        results['right_hits@{}'.format(k + 1)] = round(right_results['hits@{}'.format(k + 1)] / count, 5)\n","        results['hits@{}'.format(k + 1)] = round(\n","            (left_results['hits@{}'.format(k + 1)] + right_results['hits@{}'.format(k + 1)]) / (2 * count), 5)\n","    \n","    return results"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.181965Z","iopub.status.busy":"2023-08-29T11:31:27.181663Z","iopub.status.idle":"2023-08-29T11:31:27.190412Z","shell.execute_reply":"2023-08-29T11:31:27.189391Z","shell.execute_reply.started":"2023-08-29T11:31:27.181922Z"},"id":"RTkgcPvv7Ar2","trusted":true},"outputs":[],"source":["def get_param(shape):\n","    param = Parameter(torch.Tensor(*shape));\n","    xavier_normal_(param.data)\n","    return param"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.197576Z","iopub.status.busy":"2023-08-29T11:31:27.196218Z","iopub.status.idle":"2023-08-29T11:31:27.204496Z","shell.execute_reply":"2023-08-29T11:31:27.203412Z","shell.execute_reply.started":"2023-08-29T11:31:27.197538Z"},"id":"tYII-Atn7DUv","trusted":true},"outputs":[],"source":["def com_mult(a, b):\n","    r1, i1 = a[..., 0], a[..., 1]\n","    r2, i2 = b[..., 0], b[..., 1]\n","    return torch.stack([r1 * r2 - i1 * i2, r1 * i2 + i1 * r2], dim=-1)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.206584Z","iopub.status.busy":"2023-08-29T11:31:27.206193Z","iopub.status.idle":"2023-08-29T11:31:27.216648Z","shell.execute_reply":"2023-08-29T11:31:27.215694Z","shell.execute_reply.started":"2023-08-29T11:31:27.206548Z"},"id":"bH4wzAEr7FXF","trusted":true},"outputs":[],"source":["def conj(a):\n","    a[..., 1] = -a[..., 1]\n","    return a"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.218787Z","iopub.status.busy":"2023-08-29T11:31:27.218418Z","iopub.status.idle":"2023-08-29T11:31:27.227051Z","shell.execute_reply":"2023-08-29T11:31:27.226030Z","shell.execute_reply.started":"2023-08-29T11:31:27.218753Z"},"id":"r4r4af827HLG","trusted":true},"outputs":[],"source":["def cconv(a, b):\n","    return torch.irfft(com_mult(torch.rfft(a, 1), torch.rfft(b, 1)), 1, signal_sizes=(a.shape[-1],))"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.229173Z","iopub.status.busy":"2023-08-29T11:31:27.228572Z","iopub.status.idle":"2023-08-29T11:31:27.237172Z","shell.execute_reply":"2023-08-29T11:31:27.236499Z","shell.execute_reply.started":"2023-08-29T11:31:27.229137Z"},"id":"Z3rH21zN7IrH","trusted":true},"outputs":[],"source":["def ccorr(a, b):\n","    return torch.irfft(com_mult(conj(torch.rfft(a, 1)), torch.rfft(b, 1)), 1, signal_sizes=(a.shape[-1],))"]},{"cell_type":"markdown","metadata":{"id":"4f5QWVTNfhGY"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"D36lnInwfazg"},"source":["### SpecialSpmmFinal"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.239673Z","iopub.status.busy":"2023-08-29T11:31:27.238847Z","iopub.status.idle":"2023-08-29T11:31:27.251779Z","shell.execute_reply":"2023-08-29T11:31:27.250606Z","shell.execute_reply.started":"2023-08-29T11:31:27.239626Z"},"id":"fXzV5SPIfi-6","trusted":true},"outputs":[],"source":["class SpecialSpmmFunctionFinal(torch.autograd.Function):\n","    \"\"\"Special function for only sparse region backpropataion layer.\"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, edge, edge_w, size1, size2, out_features, dim):\n","        # assert indices.requires_grad == False\n","        # assert not torch.isnan(edge).any()\n","        # assert not torch.isnan(edge_w).any()\n","        a = torch.sparse_coo_tensor(\n","            edge, edge_w, torch.Size([size1, size2, out_features]))\n","        b = torch.sparse.sum(a, dim=dim)\n","        ctx.size1 = b.shape[0]\n","        ctx.outfeat = b.shape[1]\n","        ctx.size2 = size2\n","        if dim == 0:\n","            ctx.indices = a._indices()[1, :]\n","        else:\n","            ctx.indices = a._indices()[0, :]\n","        return b.to_dense()\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        grad_values = None\n","        if ctx.needs_input_grad[1]:\n","            edge_sources = ctx.indices\n","            if torch.cuda.is_available():\n","                edge_sources = edge_sources.cuda()\n","\n","            grad_values = grad_output[edge_sources]\n","            # grad_values = grad_values.view(ctx.E, ctx.outfeat)\n","            # print(\"Grad Outputs-> \", grad_output)\n","            # print(\"Grad values-> \", grad_values)\n","        return None, grad_values, None, None, None, None"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.263119Z","iopub.status.busy":"2023-08-29T11:31:27.261055Z","iopub.status.idle":"2023-08-29T11:31:27.269443Z","shell.execute_reply":"2023-08-29T11:31:27.268388Z","shell.execute_reply.started":"2023-08-29T11:31:27.263087Z"},"id":"YbyQZMTJfnNy","trusted":true},"outputs":[],"source":["class SpecialSpmmFinal(torch.nn.Module):\n","    def forward(self, edge, edge_w, size1, size2, out_features, dim=1):\n","        return SpecialSpmmFunctionFinal.apply(edge, edge_w, size1, size2, out_features, dim)"]},{"cell_type":"markdown","metadata":{"id":"-dT_NoSQftCS"},"source":["### Message Passing"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.271600Z","iopub.status.busy":"2023-08-29T11:31:27.271300Z","iopub.status.idle":"2023-08-29T11:31:27.282521Z","shell.execute_reply":"2023-08-29T11:31:27.281562Z","shell.execute_reply.started":"2023-08-29T11:31:27.271576Z"},"id":"8RTgKOe7f5ls","trusted":true},"outputs":[],"source":["def scatter_(name, src, index, dim_size=None):\n","    r\"\"\"Aggregates all values from the :attr:`src` tensor at the indices\n","    specified in the :attr:`index` tensor along the first dimension.\n","    If multiple indices reference the same location, their contributions\n","    are aggregated according to :attr:`name` (either :obj:`\"add\"`,\n","    :obj:`\"mean\"` or :obj:`\"max\"`).\n","    Args:\n","        name (string): The aggregation to use (:obj:`\"add\"`, :obj:`\"mean\"`,\n","            :obj:`\"max\"`).\n","        src (Tensor): The source tensor.\n","        index (LongTensor): The indices of elements to scatter.\n","        dim_size (int, optional): Automatically create output tensor with size\n","            :attr:`dim_size` in the first dimension. If set to :attr:`None`, a\n","            minimal sized output tensor is returned. (default: :obj:`None`)\n","    :rtype: :class:`Tensor`\n","    \"\"\"\n","    if name == 'add':\n","        name = 'sum'\n","    assert name in ['sum', 'mean', 'max']\n","    spm = SpecialSpmmFinal()\n","    # out = scatter(src, index, dim=0, out=None, dim_size=dim_size, reduce=name)\n","    out = spm((index.cpu().numpy(), list(range(src.shape[0]))), src, dim_size, src.shape[0], src.shape[1], dim=1)\n","    return out[0] if isinstance(out, tuple) else out"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.285144Z","iopub.status.busy":"2023-08-29T11:31:27.284404Z","iopub.status.idle":"2023-08-29T11:31:27.301482Z","shell.execute_reply":"2023-08-29T11:31:27.300398Z","shell.execute_reply.started":"2023-08-29T11:31:27.285105Z"},"id":"N5P7qhR5fnwo","trusted":true},"outputs":[],"source":["class MessagePassing(torch.nn.Module):\n","    r\"\"\"Base class for creating message passing layers\n","    .. math::\n","        \\mathbf{x}_i^{\\prime} = \\gamma_{\\mathbf{\\Theta}} \\left( \\mathbf{x}_i,\n","        \\square_{j \\in \\mathcal{N}(i)} \\, \\phi_{\\mathbf{\\Theta}}\n","        \\left(\\mathbf{x}_i, \\mathbf{x}_j,\\mathbf{e}_{i,j}\\right) \\right),\n","    where :math:`\\square` denotes a differentiable, permutation invariant\n","    function, *e.g.*, sum, mean or max, and :math:`\\gamma_{\\mathbf{\\Theta}}`\n","    and :math:`\\phi_{\\mathbf{\\Theta}}` denote differentiable functions such as\n","    MLPs.\n","    See `here <https://rusty1s.github.io/pytorch_geometric/build/html/notes/\n","    create_gnn.html>`__ for the accompanying tutorial.\n","    \"\"\"\n","\n","    def __init__(self, aggr='add'):\n","        super(MessagePassing, self).__init__()\n","        # In the defined message function: get the list of arguments as list of string|\n","        # For eg. in rgcn this will be ['x_j', 'edge_type', 'edge_norm'] (arguments of message function)\n","        self.message_args = inspect.getargspec(self.message)[0][1:]\n","        # Same for update function starting from 3rd argument | first=self, second=out\n","        self.update_args = inspect.getargspec(self.update)[0][2:]\n","\n","    def propagate(self, aggr, edge_index, **kwargs):\n","        r\"\"\"The initial call to start propagating messages.\n","        Takes in an aggregation scheme (:obj:`\"add\"`, :obj:`\"mean\"` or\n","        :obj:`\"max\"`), the edge indices, and all additional data which is\n","        needed to construct messages and to update node embeddings.\"\"\"\n","\n","        assert aggr in ['add', 'mean', 'max']\n","        kwargs['edge_index'] = edge_index\n","\n","        size = None\n","        message_args = []\n","        for arg in self.message_args:\n","            if arg[-2:] == '_i':  # If arguments ends with _i then include indic\n","                tmp = kwargs[arg[:-2]]  # Take the front part of the variable | Mostly it will be 'x',\n","                size = tmp.size(0)\n","                message_args.append(tmp[edge_index[0]])  # Lookup for head entities in edges\n","            elif arg[-2:] == '_j':\n","                tmp = kwargs[arg[:-2]]  # tmp = kwargs['x']\n","                size = tmp.size(0)\n","                message_args.append(tmp[edge_index[1]])  # Lookup for tail entities in edges\n","            else:\n","                message_args.append(kwargs[arg])  # Take things from kwargs\n","\n","        update_args = [kwargs[arg] for arg in self.update_args]  # Take update args from kwargs\n","\n","        out = self.message(*message_args)\n","        if self.p.att is None:\n","            out = scatter_(aggr, out, edge_index[0], dim_size=size)  # Aggregated neighbors for each vertex\n","        out = self.update(out, *update_args)\n","\n","        return out\n","\n","    def message(self, x_j):  # pragma: no cover\n","        r\"\"\"Constructs messages in analogy to :math:`\\phi_{\\mathbf{\\Theta}}`\n","        for each edge in :math:`(i,j) \\in \\mathcal{E}`.\n","        Can take any argument which was initially passed to :meth:`propagate`.\n","        In addition, features can be lifted to the source node :math:`i` and\n","        target node :math:`j` by appending :obj:`_i` or :obj:`_j` to the\n","        variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\"\"\"\n","\n","        return x_j\n","\n","    def update(self, aggr_out):  # pragma: no cover\n","        r\"\"\"Updates node embeddings in analogy to\n","        :math:`\\gamma_{\\mathbf{\\Theta}}` for each node\n","        :math:`i \\in \\mathcal{V}`.\n","        Takes in the output of aggregation as first argument and any argument\n","        which was initially passed to :meth:`propagate`.\"\"\"\n","\n","        return aggr_out"]},{"cell_type":"markdown","metadata":{"id":"ZxPcWbEdgp0t"},"source":["### RAGAT Conv"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.304073Z","iopub.status.busy":"2023-08-29T11:31:27.303447Z","iopub.status.idle":"2023-08-29T11:31:27.358660Z","shell.execute_reply":"2023-08-29T11:31:27.357558Z","shell.execute_reply.started":"2023-08-29T11:31:27.304035Z"},"id":"slZWnYtDgrxu","trusted":true},"outputs":[],"source":["class RagatConv(MessagePassing):\n","    def __init__(self, edge_index, edge_type, in_channels, out_channels, num_rels, act=lambda x: x, params=None,\n","                 head_num=1):\n","        super(self.__class__, self).__init__()\n","\n","        self.edge_index = edge_index\n","        self.edge_type = edge_type\n","        self.p = params\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.num_rels = num_rels\n","        self.act = act\n","        self.device = None\n","        self.head_num = head_num\n","\n","        self.w_rel = get_param((in_channels, out_channels))\n","        self.loop_rel = get_param((1, in_channels))\n","\n","        self.drop = torch.nn.Dropout(self.p.dropout)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.bn = torch.nn.BatchNorm1d(out_channels)\n","\n","        if self.p.bias:\n","            self.register_parameter('bias', Parameter(torch.zeros(out_channels)))\n","        self.special_spmm = SpecialSpmmFinal()\n","\n","        self.w_att_head1 = get_param((out_channels, 1))\n","\n","        num_edges = self.edge_index.size(1) // 2\n","        if self.device is None:\n","            self.device = self.edge_index.device\n","        self.in_index, self.out_index = self.edge_index[:, :num_edges], self.edge_index[:, num_edges:]\n","        self.in_type, self.out_type = self.edge_type[:num_edges], self.edge_type[num_edges:]\n","        self.loop_index = torch.stack([torch.arange(self.p.num_ent), torch.arange(self.p.num_ent)]).to(self.device)\n","        self.loop_type = torch.full((self.p.num_ent,), 2 * self.num_rels, dtype=torch.long).to(self.device)\n","        # E * 1, norm A\n","        num_ent = self.p.num_ent\n","        self.in_norm = None if self.p.att else self.compute_norm(self.in_index, num_ent)\n","        self.out_norm = None if self.p.att else self.compute_norm(self.out_index, num_ent)\n","\n","        self.leakyrelu = torch.nn.LeakyReLU(0.2)\n","        self.rel_weight1 = get_param((2 * self.num_rels + 1, out_channels))\n","        self.tnodes1 = get_param((in_channels, out_channels))\n","        self.trels1 = get_param((in_channels, out_channels))\n","        if self.head_num == 2 or self.head_num == 3:\n","            self.w_att_head2 = get_param((out_channels, 1))\n","            self.rel_weight2 = get_param((2 * self.num_rels + 1, out_channels))\n","            self.tnodes2 = get_param((in_channels, out_channels))\n","            self.trels2 = get_param((in_channels, out_channels))\n","\n","        if self.head_num == 3:\n","            self.tnodes3 = get_param((in_channels, out_channels))\n","            self.trels3 = get_param((in_channels, out_channels))\n","            self.w_att_head3 = get_param((out_channels, 1))\n","            self.rel_weight3 = get_param((2 * self.num_rels + 1, out_channels))\n","\n","    def forward(self, x, rel_embed):\n","        rel_embed = torch.cat([rel_embed, self.loop_rel], dim=0)\n","        # 2 * num_ent\n","        m_in1, in_res1 = self.propagate('add', self.in_index, x=x, edge_type=self.in_type, rel_embed=rel_embed,\n","                                 rel_weight=self.rel_weight1, edge_norm=self.in_norm, head=1)\n","        m_loop1, loop_res1 = self.propagate('add', self.loop_index, x=x, edge_type=self.loop_type, rel_embed=rel_embed,\n","                                   rel_weight=self.rel_weight1, edge_norm=None, head=1)\n","        m_out1, out_res1 = self.propagate('add', self.out_index, x=x, edge_type=self.out_type, rel_embed=rel_embed,\n","                                  rel_weight=self.rel_weight1, edge_norm=self.out_norm, head=1)\n","        if self.head_num == 2 or self.head_num == 3:\n","            m_in2, in_res2 = self.propagate('add', self.in_index, x=x, edge_type=self.in_type, rel_embed=rel_embed,\n","                                     rel_weight=self.rel_weight2, edge_norm=self.in_norm, head=2)\n","            m_loop2, loop_res2 = self.propagate('add', self.loop_index, x=x, edge_type=self.loop_type, rel_embed=rel_embed,\n","                                       rel_weight=self.rel_weight2, edge_norm=None, head=2)\n","            m_out2, out_res2 = self.propagate('add', self.out_index, x=x, edge_type=self.out_type, rel_embed=rel_embed,\n","                                      rel_weight=self.rel_weight2, edge_norm=self.out_norm, head=2)\n","        if self.head_num == 3:\n","            m_in3, in_res3 = self.propagate('add', self.in_index, x=x, edge_type=self.in_type, rel_embed=rel_embed,\n","                                     rel_weight=self.rel_weight3, edge_norm=self.in_norm, head=3)\n","            m_loop3, loop_res3 = self.propagate('add', self.loop_index, x=x, edge_type=self.loop_type, rel_embed=rel_embed,\n","                                       rel_weight=self.rel_weight3, edge_norm=None, head=3)\n","            m_out3, out_res3 = self.propagate('add', self.out_index, x=x, edge_type=self.out_type, rel_embed=rel_embed,\n","                                      rel_weight=self.rel_weight3, edge_norm=self.out_norm, head=3)\n","        if self.p.att:\n","            out1 = self.agg_multi_head(m_in1, m_out1, m_loop1, in_res1, out_res1, loop_res1, 1)\n","            if self.head_num == 2:\n","                out2 = self.agg_multi_head(m_in2, m_out2, m_loop2, in_res2, out_res2, loop_res2, 2)\n","                out = 1 / 2 * (out1 + out2)\n","            elif self.head_num == 3:\n","                out2 = self.agg_multi_head(m_in2, m_out2, m_loop2, in_res2, out_res2, loop_res2, 2)\n","                out3 = self.agg_multi_head(m_in3, m_out3, m_loop3, in_res3, out_res3, loop_res3, 3)\n","                out = 1 / 3 * (out1 + out2 + out3)\n","            else:\n","                out = out1\n","        else:\n","            out = self.drop(in_res1) * (1 / 3) + self.drop(out_res1) * (1 / 3) + loop_res1 * (1 / 3)\n","        if self.p.bias:\n","            out = out + self.bias\n","        relation1 = rel_embed.mm(self.w_rel)\n","        out = self.bn(out)\n","        entity1 = self.act(out)\n","\n","        return entity1, relation1[:-1]\n","\n","    def agg_multi_head(self, m_in, m_out, m_loop, att_in, att_out, att_loop, head_no):\n","        att_weight = getattr(self, 'w_att_head{}'.format(head_no))\n","        all_att = torch.cat([att_in, att_out, att_loop], dim=0)\n","        powers = -self.leakyrelu(all_att).mm(att_weight).squeeze()\n","        edge_exp = torch.exp(powers).unsqueeze(1)\n","        edge_index = torch.cat([self.edge_index, self.loop_index], dim=1)\n","        weights_rowsum = self.special_spmm(edge_index, edge_exp, self.p.num_ent, self.p.num_ent, 1, dim=1)\n","        weights_rowsum[weights_rowsum == 0] = 1\n","        edge_exp = self.drop(edge_exp)\n","        all_messages = torch.cat([m_in, m_out, m_loop], dim=0)\n","        att_messages = edge_exp * all_messages\n","        emb_agg = self.special_spmm(edge_index, att_messages, self.p.num_ent, self.p.num_ent, all_messages.shape[1], dim=1)\n","        emb_agg = emb_agg.div(weights_rowsum)\n","        assert not torch.isnan(emb_agg).any()\n","        return emb_agg\n","\n","    def rel_transform(self, ent_embed, rel_embed, rel_weight, opn=None):\n","        if opn is None:\n","            opn = self.p.opn\n","        if opn == 'corr':\n","            trans_embed = ccorr(ent_embed, rel_embed)\n","        elif opn == 'corr_ra':\n","            trans_embed = ccorr(ent_embed * rel_weight, rel_embed)\n","        elif opn == 'sub':\n","            trans_embed = ent_embed - rel_embed\n","        elif opn == 'es':\n","            trans_embed = ent_embed\n","        elif opn == 'sub_ra':\n","            trans_embed = ent_embed * rel_weight - rel_embed\n","        elif opn == 'mult':\n","            trans_embed = ent_embed * rel_embed\n","        elif opn == 'mult_ra':\n","            trans_embed = (ent_embed * rel_embed) * rel_weight\n","        elif opn == 'cross':\n","            trans_embed = ent_embed * rel_embed * rel_weight + ent_embed * rel_weight\n","        elif opn == 'cross_wo_rel':\n","            trans_embed = ent_embed * rel_weight\n","        elif opn == 'cross_simplfy':\n","            trans_embed = ent_embed * rel_embed + ent_embed\n","        elif opn == 'concat':\n","            trans_embed = torch.cat([ent_embed, rel_embed], dim=1)\n","        elif opn == 'concat_ra':\n","            trans_embed = torch.cat([ent_embed, rel_embed], dim=1) * rel_weight\n","        elif opn == 'ent_ra':\n","            trans_embed = ent_embed * rel_weight + rel_embed\n","        else:\n","            raise NotImplementedError\n","\n","        return trans_embed\n","\n","    def message(self, x_i, x_j, edge_type, rel_embed, rel_weight, edge_norm, head):\n","        rel_weights_h = getattr(self, 'rel_weight'+str(head))\n","        W_t_nodes_h = getattr(self, 'tnodes'+str(head))\n","        W_t_rels_h = getattr(self, 'trels'+str(head))\n","\n","        # getting the relation embeddings\n","        e_r = torch.index_select(rel_embed, 0, edge_type)\n","        # getting the relation specific weights\n","        w_r = torch.index_select(rel_weights_h, 0, edge_type)\n","        # transforming the neighbour node embedding\n","       \n","        e_j_t = torch.mm(x_j, W_t_nodes_h)\n","        # transforming the relation embedding\n","        e_r_t = torch.mm(e_r, W_t_rels_h)\n","        # constructing the message\n","        c_jr = self.rel_transform(e_j_t, e_r_t, w_r)\n","        \n","        if self.p.att:\n","            # concatenating the node embeddings and the relation embedding\n","            cat_emb = torch.cat([x_i, e_r, x_j], dim=1)\n","            \n","            # concatenating the transformation weights\n","            cat_w_t = torch.cat([W_t_nodes_h, W_t_rels_h, W_t_nodes_h], dim=0)\n","\n","            # multiplying the concatenated embeddings with the concatenated weights\n","            att_out = torch.mm(cat_emb, cat_w_t)\n","            \n","            return c_jr, att_out\n","        else:\n","            return c_jr*edge_norm.view(-1, 1), None\n","\n","    def update(self, aggr_out):\n","        return aggr_out\n","\n","    def compute_norm(self, edge_index, num_ent):\n","        row, col = edge_index\n","        edge_weight = torch.ones_like(row).float().unsqueeze(1)\n","        deg = self.special_spmm((row.cpu().numpy(), col.cpu().numpy()), edge_weight, num_ent, num_ent, 1, dim=1)\n","        deg_inv = deg.pow(-0.5)  # D^{-0.5}\n","        deg_inv[deg_inv == float('inf')] = 0\n","        norm = deg_inv[row] * edge_weight * deg_inv[col]  # D^{-0.5}\n","\n","        return norm\n","\n","    def __repr__(self):\n","        return '{}({}, {}, num_rels={})'.format(\n","            self.__class__.__name__, self.in_channels, self.out_channels, self.num_rels)"]},{"cell_type":"markdown","metadata":{"id":"-yNK8UepgI2H"},"source":["### Models"]},{"cell_type":"markdown","metadata":{"id":"zrdVip8mgSAb"},"source":["#### Base Model"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.361928Z","iopub.status.busy":"2023-08-29T11:31:27.361111Z","iopub.status.idle":"2023-08-29T11:31:27.375379Z","shell.execute_reply":"2023-08-29T11:31:27.374263Z","shell.execute_reply.started":"2023-08-29T11:31:27.361889Z"},"id":"Pa09eZj2gKtg","trusted":true},"outputs":[],"source":["class BaseModel(torch.nn.Module):\n","    def __init__(self, params):\n","        super(BaseModel, self).__init__()\n","\n","        self.p = params\n","        self.act = torch.tanh\n","        self.bceloss = torch.nn.BCELoss()\n","\n","    def loss(self, pred, true_label):\n","        return self.bceloss(pred, true_label)"]},{"cell_type":"markdown","metadata":{"id":"oE2v9XA-gToK"},"source":["#### RAGAT Base"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.377572Z","iopub.status.busy":"2023-08-29T11:31:27.377020Z","iopub.status.idle":"2023-08-29T11:31:27.398579Z","shell.execute_reply":"2023-08-29T11:31:27.397395Z","shell.execute_reply.started":"2023-08-29T11:31:27.377532Z"},"id":"wuUOOOy6gOYP","trusted":true},"outputs":[],"source":["class RagatBase(BaseModel):\n","    def __init__(self, edge_index, edge_type, num_rel, params=None):\n","        #super(RagatBase, self).__init__(params)\n","        super().__init__(params)\n","\n","        self.edge_index = edge_index\n","        self.edge_type = edge_type\n","        self.p.gcn_dim = self.p.embed_dim if self.p.gcn_layer == 1 else self.p.gcn_dim\n","        self.init_embed = get_param((self.p.num_ent, self.p.init_dim))\n","        self.device = self.edge_index.device\n","\n","        if self.p.score_func == 'transe':\n","            self.init_rel = get_param((num_rel, self.p.init_dim))\n","        else:\n","            self.init_rel = get_param((num_rel * 2, self.p.init_dim))\n","\n","        self.conv1 = RagatConv(self.edge_index, self.edge_type, self.p.init_dim, self.p.gcn_dim, num_rel,\n","                               act=self.act, params=self.p, head_num=self.p.head_num)\n","        self.conv2 = RagatConv(self.edge_index, self.edge_type, self.p.gcn_dim, self.p.embed_dim, num_rel,\n","                               act=self.act, params=self.p, head_num=1) if self.p.gcn_layer == 2 else None\n","\n","        self.register_parameter('bias', Parameter(torch.zeros(self.p.num_ent)))\n","        self.special_spmm = SpecialSpmmFinal()\n","        self.rel_drop = torch.nn.Dropout(0.1)\n","\n","    def forward_base(self, sub, rel, drop1, drop2):\n","        # r: (2 * num_relation) x init_dim\n","        init_rel = self.init_rel if self.p.score_func != 'transe' else torch.cat([self.init_rel, -self.init_rel], dim=0)\n","        ent_embed1, rel_embed1 = self.conv1(x=self.init_embed, rel_embed=init_rel)\n","        ent_embed1 = drop1(ent_embed1)\n","\n","        ent_embed2, rel_embed2 = self.conv2(x=ent_embed1, rel_embed=rel_embed1) if self.p.gcn_layer == 2 else (\n","            ent_embed1, rel_embed1)\n","        ent_embed2 = drop2(ent_embed2) if self.p.gcn_layer == 2 else ent_embed1\n","\n","        final_ent = ent_embed2 if self.p.gcn_layer == 2 else ent_embed1\n","        final_rel = rel_embed2 if self.p.gcn_layer == 2 else rel_embed1\n","        sub_emb = torch.index_select(final_ent, 0, sub)\n","        rel_emb = torch.index_select(final_rel, 0, rel)\n","        return sub_emb, rel_emb, final_ent\n","\n","    def gather_neighbours(self):\n","        edge_weight = torch.ones_like(self.edge_type).float().unsqueeze(1)\n","        deg = self.special_spmm(self.edge_index, edge_weight, self.p.num_ent, self.p.num_ent, 1,\n","                                dim=1)\n","        deg[deg == 0.0] = 1.0\n","        entity_neighbours = self.init_embed[self.edge_index[1, :], :]\n","        entity_gathered = self.special_spmm(\n","            self.edge_index, entity_neighbours, self.p.num_ent, self.p.num_ent, self.p.init_dim,\n","            dim=1).div(deg)\n","        relation_neighbours = torch.index_select(self.init_rel, 0, self.edge_type)\n","        relation_gathered = self.special_spmm(\n","            self.edge_index, relation_neighbours, self.p.num_ent, self.p.num_ent, self.p.init_dim, dim=1).div(deg)\n","        return entity_gathered, relation_gathered"]},{"cell_type":"markdown","metadata":{"id":"GmEK5xjDgXOz"},"source":["#### RAGAT TransE"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.400795Z","iopub.status.busy":"2023-08-29T11:31:27.400267Z","iopub.status.idle":"2023-08-29T11:31:27.414239Z","shell.execute_reply":"2023-08-29T11:31:27.413192Z","shell.execute_reply.started":"2023-08-29T11:31:27.400757Z"},"id":"NDR8fmrLgbtr","trusted":true},"outputs":[],"source":["class RagatTransE(RagatBase):\n","    def __init__(self, edge_index, edge_type, params=None):\n","        super(self.__class__, self).__init__(edge_index, edge_type, params.num_rel, params)\n","        self.drop = torch.nn.Dropout(self.p.hid_drop)\n","\n","    def forward(self, sub, rel):\n","        sub_emb, rel_emb, all_ent = self.forward_base(sub, rel, self.drop, self.drop)\n","        obj_emb = sub_emb + rel_emb\n","\n","        x = self.p.gamma - torch.norm(obj_emb.unsqueeze(1) - all_ent, p=1, dim=2)\n","        score = torch.sigmoid(x)\n","\n","        return score"]},{"cell_type":"markdown","metadata":{"id":"8o1okaZwgbKi"},"source":["#### RAGAT DistMult"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.416549Z","iopub.status.busy":"2023-08-29T11:31:27.415842Z","iopub.status.idle":"2023-08-29T11:31:27.425851Z","shell.execute_reply":"2023-08-29T11:31:27.424646Z","shell.execute_reply.started":"2023-08-29T11:31:27.416509Z"},"id":"blA2UaHPgfV1","trusted":true},"outputs":[],"source":["class RagatDistMult(RagatBase):\n","    def __init__(self, edge_index, edge_type, params=None):\n","        super(self.__class__, self).__init__(edge_index, edge_type, params.num_rel, params)\n","        self.drop = torch.nn.Dropout(self.p.hid_drop)\n","\n","    def forward(self, sub, rel):\n","        sub_emb, rel_emb, all_ent = self.forward_base(sub, rel, self.drop, self.drop)\n","        obj_emb = sub_emb * rel_emb\n","\n","        x = torch.mm(obj_emb, all_ent.transpose(1, 0))\n","        x += self.bias.expand_as(x)\n","\n","        score = torch.sigmoid(x)\n","        return "]},{"cell_type":"markdown","metadata":{"id":"lcT_eLVtgfxJ"},"source":["#### RAGAT ConvE"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.428188Z","iopub.status.busy":"2023-08-29T11:31:27.427743Z","iopub.status.idle":"2023-08-29T11:31:27.446228Z","shell.execute_reply":"2023-08-29T11:31:27.445487Z","shell.execute_reply.started":"2023-08-29T11:31:27.428153Z"},"id":"8TPByQc6gjQ5","trusted":true},"outputs":[],"source":["class RagatConvE(RagatBase):\n","    def __init__(self, edge_index, edge_type, params=None):\n","        super(self.__class__, self).__init__(edge_index, edge_type, params.num_rel, params)\n","        self.embed_dim = self.p.embed_dim\n","\n","        self.bn0 = torch.nn.BatchNorm2d(1)\n","        self.bn1 = torch.nn.BatchNorm2d(self.p.num_filt)\n","        self.bn2 = torch.nn.BatchNorm1d(self.embed_dim)\n","\n","        self.hidden_drop = torch.nn.Dropout(self.p.hid_drop)\n","        self.hidden_drop2 = torch.nn.Dropout(self.p.hid_drop2)\n","        self.feature_drop = torch.nn.Dropout(self.p.feat_drop)\n","        self.m_conv1 = torch.nn.Conv2d(1, out_channels=self.p.num_filt, kernel_size=(self.p.ker_sz, self.p.ker_sz),\n","                                       stride=1, padding=0, bias=self.p.bias)\n","\n","        flat_sz_h = int(2 * self.p.k_w) - self.p.ker_sz + 1\n","        flat_sz_w = self.p.k_h - self.p.ker_sz + 1\n","        self.flat_sz = flat_sz_h * flat_sz_w * self.p.num_filt\n","        self.fc = torch.nn.Linear(self.flat_sz, self.embed_dim)\n","\n","    def concat(self, e1_embed, rel_embed):\n","        e1_embed = e1_embed.view(-1, 1, self.embed_dim)\n","        rel_embed = rel_embed.view(-1, 1, self.embed_dim)\n","        stack_inp = torch.cat([e1_embed, rel_embed], 1)\n","        stack_inp = torch.transpose(stack_inp, 2, 1).reshape((-1, 1, 2 * self.p.k_w, self.p.k_h))\n","        return stack_inp\n","\n","    def forward(self, sub, rel, neg_ents=None):\n","        sub_emb, rel_emb, all_ent = self.forward_base(sub, rel, self.hidden_drop, self.feature_drop)\n","        stk_inp = self.concat(sub_emb, rel_emb)\n","        x = self.bn0(stk_inp)\n","        x = self.m_conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.feature_drop(x)\n","        x = x.view(-1, self.flat_sz)\n","        x = self.fc(x)\n","        x = self.hidden_drop2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","\n","        x = torch.mm(x, all_ent.transpose(1, 0))\n","        x += self.bias.expand_as(x)\n","\n","        score = torch.sigmoid(x)\n","        return score"]},{"cell_type":"markdown","metadata":{"id":"aTIGytQ8gj0g"},"source":["#### RAGAT IntractE"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.448362Z","iopub.status.busy":"2023-08-29T11:31:27.447729Z","iopub.status.idle":"2023-08-29T11:31:27.478425Z","shell.execute_reply":"2023-08-29T11:31:27.477351Z","shell.execute_reply.started":"2023-08-29T11:31:27.448307Z"},"id":"-716vkL0gllX","trusted":true},"outputs":[],"source":["class RagatInteractE(RagatBase):\n","    def __init__(self, edge_index, edge_type, params=None):\n","        super(self.__class__, self).__init__(edge_index, edge_type, params.num_rel, params)\n","        # self.ent_embed = torch.nn.Embedding(self.p.num_ent, self.p.embed_dim, padding_idx=None)\n","        # xavier_normal_(self.ent_embed.weight)\n","        # self.rel_embed = torch.nn.Embedding(self.p.num_rel * 2, self.p.embed_dim, padding_idx=None)\n","        # xavier_normal_(self.rel_embed.weight)\n","\n","        self.inp_drop = torch.nn.Dropout(self.p.iinp_drop)\n","        self.feature_map_drop = torch.nn.Dropout2d(self.p.ifeat_drop)\n","        self.hidden_drop = torch.nn.Dropout(self.p.ihid_drop)\n","\n","        self.hidden_drop_gcn = torch.nn.Dropout(0)\n","\n","        self.bn0 = torch.nn.BatchNorm2d(self.p.iperm)\n","\n","        flat_sz_h = self.p.ik_h\n","        flat_sz_w = 2 * self.p.ik_w\n","        self.padding = 0\n","\n","        self.bn1 = torch.nn.BatchNorm2d(self.p.inum_filt * self.p.iperm)\n","        self.flat_sz = flat_sz_h * flat_sz_w * self.p.inum_filt * self.p.iperm\n","\n","        self.bn2 = torch.nn.BatchNorm1d(self.p.embed_dim)\n","        self.fc = torch.nn.Linear(self.flat_sz, self.p.embed_dim)\n","        self.chequer_perm = self.get_chequer_perm()\n","\n","        self.register_parameter('bias', Parameter(torch.zeros(self.p.num_ent)))\n","        self.register_parameter('conv_filt',\n","                                Parameter(torch.zeros(self.p.inum_filt, 1, self.p.iker_sz, self.p.iker_sz)))\n","        xavier_normal_(self.conv_filt)\n","\n","    def circular_padding_chw(self, batch, padding):\n","        upper_pad = batch[..., -padding:, :]\n","        lower_pad = batch[..., :padding, :]\n","        temp = torch.cat([upper_pad, batch, lower_pad], dim=2)\n","\n","        left_pad = temp[..., -padding:]\n","        right_pad = temp[..., :padding]\n","        padded = torch.cat([left_pad, temp, right_pad], dim=3)\n","        return padded\n","\n","    def forward(self, sub, rel, neg_ents=None):\n","        sub_emb, rel_emb, all_ent = self.forward_base(sub, rel, self.inp_drop, self.hidden_drop_gcn)\n","        comb_emb = torch.cat([sub_emb, rel_emb], dim=1)\n","        chequer_perm = comb_emb[:, self.chequer_perm]\n","        stack_inp = chequer_perm.reshape((-1, self.p.iperm, 2 * self.p.ik_w, self.p.ik_h))\n","        stack_inp = self.bn0(stack_inp)\n","        x = stack_inp\n","        x = self.circular_padding_chw(x, self.p.iker_sz // 2)\n","        x = F.conv2d(x, self.conv_filt.repeat(self.p.iperm, 1, 1, 1), padding=self.padding, groups=self.p.iperm)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.feature_map_drop(x)\n","        x = x.view(-1, self.flat_sz)\n","        x = self.fc(x)\n","        x = self.hidden_drop(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","\n","        if self.p.strategy == 'one_to_n' or neg_ents is None:\n","            x = torch.mm(x, all_ent.transpose(1, 0))\n","            x += self.bias.expand_as(x)\n","        else:\n","            x = torch.mul(x.unsqueeze(1), all_ent[neg_ents]).sum(dim=-1)\n","            x += self.bias[neg_ents]\n","\n","        pred = torch.sigmoid(x)\n","\n","        return pred\n","\n","    def get_chequer_perm(self):\n","        \"\"\"\n","        Function to generate the chequer permutation required for InteractE model\n","        Parameters\n","        ----------\n","        Returns\n","        -------\n","        \"\"\"\n","        ent_perm = np.int32([np.random.permutation(self.p.embed_dim) for _ in range(self.p.iperm)])\n","        rel_perm = np.int32([np.random.permutation(self.p.embed_dim) for _ in range(self.p.iperm)])\n","\n","        comb_idx = []\n","        for k in range(self.p.iperm):\n","            temp = []\n","            ent_idx, rel_idx = 0, 0\n","\n","            for i in range(self.p.ik_h):\n","                for j in range(self.p.ik_w):\n","                    if k % 2 == 0:\n","                        if i % 2 == 0:\n","                            temp.append(ent_perm[k, ent_idx])\n","                            ent_idx += 1\n","                            temp.append(rel_perm[k, rel_idx] + self.p.embed_dim)\n","                            rel_idx += 1\n","                        else:\n","                            temp.append(rel_perm[k, rel_idx] + self.p.embed_dim)\n","                            rel_idx += 1\n","                            temp.append(ent_perm[k, ent_idx])\n","                            ent_idx += 1\n","                    else:\n","                        if i % 2 == 0:\n","                            temp.append(rel_perm[k, rel_idx] + self.p.embed_dim)\n","                            rel_idx += 1\n","                            temp.append(ent_perm[k, ent_idx])\n","                            ent_idx += 1\n","                        else:\n","                            temp.append(ent_perm[k, ent_idx])\n","                            ent_idx += 1\n","                            temp.append(rel_perm[k, rel_idx] + self.p.embed_dim)\n","                            rel_idx += 1\n","\n","            comb_idx.append(temp)\n","\n","        chequer_perm = torch.LongTensor(np.int32(comb_idx)).to(self.device)\n","        return chequer_perm"]},{"cell_type":"markdown","metadata":{"id":"HcquDhCB3v2r"},"source":["## Run"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.480846Z","iopub.status.busy":"2023-08-29T11:31:27.480302Z","iopub.status.idle":"2023-08-29T11:31:27.559248Z","shell.execute_reply":"2023-08-29T11:31:27.557861Z","shell.execute_reply.started":"2023-08-29T11:31:27.480809Z"},"id":"gQn2Ljcazl-V","trusted":true},"outputs":[],"source":["class Runner(object):\n","    def __init__(self, params):\n","        \"\"\"\n","        Constructor of the runner class\n","        Parameters\n","        ----------\n","        params:         List of hyper-parameters of the model\n","        Returns\n","        -------\n","        Creates computational graph and optimizer\n","        \"\"\"\n","        self.p = params\n","        self.logger = get_logger(self.p.name, self.p.log_dir, self.p.config_dir)\n","\n","        self.logger.info(vars(self.p))\n","        pprint(vars(self.p))\n","\n","        if self.p.gpu != '-1' and torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","            torch.cuda.set_rng_state(torch.cuda.get_rng_state())\n","            torch.backends.cudnn.deterministic = True\n","        else:\n","            self.device = torch.device('cpu')\n","\n","        self.load_data()\n","        self.model = self.add_model(self.p.model, self.p.score_func)\n","        self.optimizer = self.add_optimizer(self.model.parameters())\n","\n","\n","    def load_data(self):\n","        \"\"\"\n","        Reading in raw triples and converts it into a standard format.\n","        Parameters\n","        ----------\n","        self.p.dataset:         Takes in the name of the dataset (FB15k-237)\n","        Returns\n","        -------\n","        self.ent2id:            Entity to unique identifier mapping\n","        self.id2rel:            Inverse mapping of self.ent2id\n","        self.rel2id:            Relation to unique identifier mapping\n","        self.num_ent:           Number of entities in the Knowledge graph\n","        self.num_rel:           Number of relations in the Knowledge graph\n","        self.embed_dim:         Embedding dimension used\n","        self.data['train']:     Stores the triples corresponding to training dataset\n","        self.data['valid']:     Stores the triples corresponding to validation dataset\n","        self.data['test']:      Stores the triples corresponding to test dataset\n","        self.data_iter:\t\tThe dataloader for different data splits\n","        \"\"\"\n","\n","        ent_set, rel_set = OrderedSet(), OrderedSet()\n","        for split in ['train', 'test', 'valid']:\n","            for line in open('./data/{}/{}.txt'.format(self.p.dataset, split)):\n","                sub, rel, obj = map(str.lower, line.strip().split('\\t'))\n","                ent_set.add(sub)\n","                rel_set.add(rel)\n","                ent_set.add(obj)\n","\n","        self.ent2id = {ent: idx for idx, ent in enumerate(ent_set)}\n","        self.rel2id = {rel: idx for idx, rel in enumerate(rel_set)}\n","        self.rel2id.update({rel + '_reverse': idx + len(self.rel2id) for idx, rel in enumerate(rel_set)})\n","\n","        self.id2ent = {idx: ent for ent, idx in self.ent2id.items()}\n","        self.id2rel = {idx: rel for rel, idx in self.rel2id.items()}\n","\n","        self.p.num_ent = len(self.ent2id)\n","        self.p.num_rel = len(self.rel2id) // 2\n","        self.p.embed_dim = self.p.k_w * self.p.k_h if self.p.embed_dim is None else self.p.embed_dim\n","\n","        self.data = ddict(list)\n","        sr2o = ddict(set)\n","\n","        for split in ['train', 'test', 'valid']:\n","            for line in open('./data/{}/{}.txt'.format(self.p.dataset, split)):\n","                sub, rel, obj = map(str.lower, line.strip().split('\\t'))\n","                sub, rel, obj = self.ent2id[sub], self.rel2id[rel], self.ent2id[obj]\n","                self.data[split].append((sub, rel, obj))\n","\n","                if split == 'train':\n","                    sr2o[(sub, rel)].add(obj)\n","                    sr2o[(obj, rel + self.p.num_rel)].add(sub)\n","        # self.data: all origin train + valid + test triplets\n","        self.data = dict(self.data)\n","        # self.sr2o: train origin edges and reverse edges\n","        self.sr2o = {k: list(v) for k, v in sr2o.items()}\n","        for split in ['test', 'valid']:\n","            for sub, rel, obj in self.data[split]:\n","                sr2o[(sub, rel)].add(obj)\n","                sr2o[(obj, rel + self.p.num_rel)].add(sub)\n","\n","        self.sr2o_all = {k: list(v) for k, v in sr2o.items()}\n","        self.triples = ddict(list)\n","\n","        # for (sub, rel), obj in self.sr2o.items():\n","        #     self.triples['train'].append({'triple': (sub, rel, -1), 'label': self.sr2o[(sub, rel)], 'sub_samp': 1})\n","        if self.p.strategy == 'one_to_n':\n","            for (sub, rel), obj in self.sr2o.items():\n","                self.triples['train'].append({'triple': (sub, rel, -1), 'label': self.sr2o[(sub, rel)], 'sub_samp': 1})\n","        else:\n","            for sub, rel, obj in self.data['train']:\n","                rel_inv = rel + self.p.num_rel\n","                sub_samp = len(self.sr2o[(sub, rel)]) + len(self.sr2o[(obj, rel_inv)])\n","                sub_samp = np.sqrt(1 / sub_samp)\n","\n","                self.triples['train'].append(\n","                    {'triple': (sub, rel, obj), 'label': self.sr2o[(sub, rel)], 'sub_samp': sub_samp})\n","                self.triples['train'].append(\n","                    {'triple': (obj, rel_inv, sub), 'label': self.sr2o[(obj, rel_inv)], 'sub_samp': sub_samp})\n","\n","        for split in ['test', 'valid']:\n","            for sub, rel, obj in self.data[split]:\n","                rel_inv = rel + self.p.num_rel\n","                self.triples['{}_{}'.format(split, 'tail')].append(\n","                    {'triple': (sub, rel, obj), 'label': self.sr2o_all[(sub, rel)]})\n","                self.triples['{}_{}'.format(split, 'head')].append(\n","                    {'triple': (obj, rel_inv, sub), 'label': self.sr2o_all[(obj, rel_inv)]})\n","\n","        self.triples = dict(self.triples)\n","\n","        def get_data_loader(dataset_class, split, batch_size, shuffle=True):\n","            return DataLoader(\n","                dataset_class(self.triples[split], self.p),\n","                batch_size=batch_size,\n","                shuffle=shuffle,\n","                num_workers=max(0, self.p.num_workers),\n","                collate_fn=dataset_class.collate_fn\n","            )\n","\n","        self.data_iter = {\n","            'train': get_data_loader(TrainDataset, 'train', self.p.batch_size),\n","            'valid_head': get_data_loader(TestDataset, 'valid_head', self.p.test_batch_size),\n","            'valid_tail': get_data_loader(TestDataset, 'valid_tail', self.p.test_batch_size),\n","            'test_head': get_data_loader(TestDataset, 'test_head', self.p.test_batch_size),\n","            'test_tail': get_data_loader(TestDataset, 'test_tail', self.p.test_batch_size),\n","        }\n","\n","        self.edge_index, self.edge_type = self.construct_adj()\n","        \n","        # print the number of nodes in the graph\n","        print('Number of nodes: {}'.format(self.p.num_ent))\n","        # print the number of relations in the graph\n","        print('Number of relations: {}'.format(self.p.num_rel))\n","        # print the number of edges in the graph\n","        print('Number of edges: {}'.format(self.edge_index.shape[1]))\n","        print('-'*100)\n","\n","    def construct_adj(self):\n","        \"\"\"\n","        Constructor of the runner class\n","        Parameters\n","        ----------\n","        Returns\n","        -------\n","        Constructs the adjacency matrix for GCN\n","        \"\"\"\n","        edge_index, edge_type = [], []\n","\n","        for sub, rel, obj in self.data['train']:\n","            edge_index.append((sub, obj))\n","            edge_type.append(rel)\n","\n","        # Adding inverse edges\n","        for sub, rel, obj in self.data['train']:\n","            edge_index.append((obj, sub))\n","            edge_type.append(rel + self.p.num_rel)\n","        # edge_index: 2 * 2E, edge_type: 2E * 1\n","        edge_index = torch.LongTensor(edge_index).to(self.device).t()\n","        edge_type = torch.LongTensor(edge_type).to(self.device)\n","\n","        return edge_index, edge_type\n","\n","    def add_model(self, model, score_func):\n","        \"\"\"\n","        Creates the computational graph\n","        Parameters\n","        ----------\n","        model_name:     Contains the model name to be created\n","        Returns\n","        -------\n","        Creates the computational graph for model and initializes it\n","        \"\"\"\n","        model_name = '{}_{}'.format(model, score_func)\n","\n","        if model_name.lower() == 'ragat_transe':\n","            model = RagatTransE(self.edge_index, self.edge_type, params=self.p)\n","        elif model_name.lower() == 'ragat_distmult':\n","            model = RagatDistMult(self.edge_index, self.edge_type, params=self.p)\n","        elif model_name.lower() == 'ragat_conve':\n","            model = RagatConvE(self.edge_index, self.edge_type, params=self.p)\n","        elif model_name.lower() == 'ragat_interacte':\n","            model = RagatInteractE(self.edge_index, self.edge_type, params=self.p)\n","        else:\n","            raise NotImplementedError\n","\n","        model.to(self.device)\n","        \n","        print('-'*100)\n","        total_params = pytorch_total_params(model)\n","        print(f\"Total number of trainable parameters: {total_params}\")\n","        print('-'*100)\n","        \n","        return model\n","\n","    def add_optimizer(self, parameters):\n","        \"\"\"\n","        Creates an optimizer for training the parameters\n","        Parameters\n","        ----------\n","        parameters:         The parameters of the model\n","        Returns\n","        -------\n","        Returns an optimizer for learning the parameters of the model\n","        \"\"\"\n","        return torch.optim.Adam(parameters, lr=self.p.lr, weight_decay=self.p.l2)\n","\n","    def read_batch(self, batch, split):\n","        \"\"\"\n","        Function to read a batch of data and move the tensors in batch to CPU/GPU\n","        Parameters\n","        ----------\n","        batch: \t\tthe batch to process\n","        split: (string) If split == 'train', 'valid' or 'test' split\n","        Returns\n","        -------\n","        Head, Relation, Tails, labels\n","        \"\"\"\n","        # if split == 'train':\n","        #     triple, label = [_.to(self.device) for _ in batch]\n","        #     return triple[:, 0], triple[:, 1], triple[:, 2], label\n","        # else:\n","        #     triple, label = [_.to(self.device) for _ in batch]\n","        #     return triple[:, 0], triple[:, 1], triple[:, 2], label\n","        if split == 'train':\n","            if self.p.strategy == 'one_to_x':\n","                triple, label, neg_ent, sub_samp = [_.to(self.device) for _ in batch]\n","                return triple[:, 0], triple[:, 1], triple[:, 2], label, neg_ent, sub_samp\n","            else:\n","                triple, label = [_.to(self.device) for _ in batch]\n","                return triple[:, 0], triple[:, 1], triple[:, 2], label, None, None\n","        else:\n","            triple, label = [_.to(self.device) for _ in batch]\n","            return triple[:, 0], triple[:, 1], triple[:, 2], label\n","\n","    def save_model(self, save_path):\n","        \"\"\"\n","        Function to save a model. It saves the model parameters, best validation scores,\n","        best epoch corresponding to best validation, state of the optimizer and all arguments for the run.\n","        Parameters\n","        ----------\n","        save_path: path where the model is saved\n","        Returns\n","        -------\n","        \"\"\"\n","        state = {\n","            'state_dict': self.model.state_dict(),\n","            'best_val': self.best_val,\n","            'best_epoch': self.best_epoch,\n","            'optimizer': self.optimizer.state_dict(),\n","            'args': vars(self.p)\n","        }\n","        torch.save(state, save_path)\n","\n","    def load_model(self, load_path):\n","        \"\"\"\n","        Function to load a saved model\n","        Parameters\n","        ----------\n","        load_path: path to the saved model\n","        Returns\n","        -------\n","        \"\"\"\n","        state = torch.load(load_path)\n","        state_dict = state['state_dict']\n","        self.best_val = state['best_val']\n","        self.best_val_mrr = self.best_val['mrr']\n","\n","        self.model.load_state_dict(state_dict)\n","        self.optimizer.load_state_dict(state['optimizer'])\n","\n","    def evaluate(self, split, epoch):\n","        \"\"\"\n","        Function to evaluate the model on validation or test set\n","        Parameters\n","        ----------\n","        split: (string) If split == 'valid' then evaluate on the validation set, else the test set\n","        epoch: (int) Current epoch count\n","        Returns\n","        -------\n","        resutls:\t\t\tThe evaluation results containing the following:\n","            results['mr']:         \tAverage of ranks_left and ranks_right\n","            results['mrr']:         Mean Reciprocal Rank\n","            results['hits@k']:      Probability of getting the correct preodiction in top-k ranks based on predicted score\n","        \"\"\"\n","        left_results = self.predict(split=split, mode='tail_batch')\n","\n","        right_results = self.predict(split=split, mode='head_batch')\n","\n","        results = get_combined_results(left_results, right_results)\n","\n","        res_mrr = '\\n\\tMRR: Tail : {:.5}, Head : {:.5}, Avg : {:.5}\\n'.format(results['left_mrr'],\n","                                                                              results['right_mrr'],\n","                                                                              results['mrr'])\n","        res_mr = '\\tMR: Tail : {:.5}, Head : {:.5}, Avg : {:.5}\\n'.format(results['left_mr'],\n","                                                                          results['right_mr'],\n","                                                                          results['mr'])\n","        res_hit1 = '\\tHit-1: Tail : {:.5}, Head : {:.5}, Avg : {:.5}\\n'.format(results['left_hits@1'],\n","                                                                               results['right_hits@1'],\n","                                                                               results['hits@1'])\n","        res_hit3 = '\\tHit-3: Tail : {:.5}, Head : {:.5}, Avg : {:.5}\\n'.format(results['left_hits@3'],\n","                                                                               results['right_hits@3'],\n","                                                                               results['hits@3'])\n","        res_hit10 = '\\tHit-10: Tail : {:.5}, Head : {:.5}, Avg : {:.5}'.format(results['left_hits@10'],\n","                                                                               results['right_hits@10'],\n","                                                                               results['hits@10'])\n","        log_res = res_mrr + res_mr + res_hit1 + res_hit3 + res_hit10\n","        if (epoch + 1) % 10 == 0 or split == 'test':\n","            self.logger.info(\n","                '[Evaluating Epoch {} {}]: {}'.format(epoch, split, log_res))\n","        else:\n","            self.logger.info(\n","                '[Evaluating Epoch {} {}]: {}'.format(epoch, split, res_mrr))\n","\n","        return results\n","\n","    def predict(self, split='valid', mode='tail_batch'):\n","        \"\"\"\n","        Function to run model evaluation for a given mode\n","        Parameters\n","        ----------\n","        split: (string) \tIf split == 'valid' then evaluate on the validation set, else the test set\n","        mode: (string):\t\tCan be 'head_batch' or 'tail_batch'\n","        Returns\n","        -------\n","        resutls:\t\t\tThe evaluation results containing the following:\n","            results['mr']:         \tAverage of ranks_left and ranks_right\n","            results['mrr']:         Mean Reciprocal Rank\n","            results['hits@k']:      Probability of getting the correct preodiction in top-k ranks based on predicted score\n","        \"\"\"\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            results = {}\n","            train_iter = iter(self.data_iter['{}_{}'.format(split, mode.split('_')[0])])\n","\n","            for step, batch in enumerate(train_iter):\n","                sub, rel, obj, label = self.read_batch(batch, split)\n","                pred = self.model.forward(sub, rel)\n","                b_range = torch.arange(pred.size()[0], device=self.device)\n","                target_pred = pred[b_range, obj]\n","                # filter setting\n","                pred = torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n","                pred[b_range, obj] = target_pred\n","                ranks = 1 + torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[\n","                    b_range, obj]\n","\n","                ranks = ranks.float()\n","                results['count'] = torch.numel(ranks) + results.get('count', 0.0)\n","                results['mr'] = torch.sum(ranks).item() + results.get('mr', 0.0)\n","                results['mrr'] = torch.sum(1.0 / ranks).item() + results.get('mrr', 0.0)\n","                for k in range(10):\n","                    results['hits@{}'.format(k + 1)] = torch.numel(ranks[ranks <= (k + 1)]) + results.get(\n","                        'hits@{}'.format(k + 1), 0.0)\n","\n","                # if step % 100 == 0:\n","                #     self.logger.info('[{}, {} Step {}]\\t{}'.format(split.title(), mode.title(), step, self.p.name))\n","\n","        return results\n","\n","    def run_epoch(self, epoch, val_mrr=0):\n","        \"\"\"\n","        Function to run one epoch of training\n","        Parameters\n","        ----------\n","        epoch: current epoch count\n","        Returns\n","        -------\n","        loss: The loss value after the completion of one epoch\n","        \"\"\"\n","        self.model.train()\n","        losses = []\n","        train_iter = iter(self.data_iter['train'])\n","\n","        for step, batch in enumerate(train_iter):\n","            self.optimizer.zero_grad()\n","            sub, rel, obj, label, neg_ent, sub_samp = self.read_batch(batch, 'train')\n","\n","            pred = self.model.forward(sub, rel, neg_ent)\n","            loss = self.model.loss(pred, label)\n","\n","            loss.backward()\n","            self.optimizer.step()\n","            losses.append(loss.item())\n","\n","            # if step % 100 == 0:\n","            #     self.logger.info('[E:{}| {}]: Train Loss:{:.5},  Val MRR:{:.5}\\t{}'.format(epoch, step, np.mean(losses),\n","            #                                                                                self.best_val_mrr,\n","            #                                                                                self.p.name))\n","\n","        loss = np.mean(losses)\n","        # self.logger.info('[Epoch:{}]:  Training Loss:{:.4}\\n'.format(epoch, loss))\n","        return loss\n","\n","    def fit(self):\n","        \"\"\"\n","        Function to run training and evaluation of model\n","        Parameters\n","        ----------\n","        Returns\n","        -------\n","        \"\"\"\n","        try:\n","            self.best_val_mrr, self.best_val, self.best_epoch, val_mrr = 0., {}, 0, 0.\n","            save_path = os.path.join('./checkpoints', self.p.name)\n","\n","            if self.p.restore:\n","                self.load_model(save_path)\n","                self.logger.info('Successfully Loaded previous model')\n","            val_results = {}\n","            val_results['mrr'] = 0\n","            for epoch in range(self.p.max_epochs):\n","                train_loss = self.run_epoch(epoch, val_mrr)\n","                # if ((epoch + 1) % 10 == 0):\n","                val_results = self.evaluate('valid', epoch)\n","\n","                if val_results['mrr'] > self.best_val_mrr:\n","                    self.best_val = val_results\n","                    self.best_val_mrr = val_results['mrr']\n","                    self.best_epoch = epoch\n","                    self.save_model(save_path)\n","\n","                self.logger.info(\n","                    '[Epoch {}]: Training Loss: {:.5}, Best valid MRR: {:.5}\\n\\n'.format(epoch, train_loss,\n","                                                                                         self.best_val_mrr))\n","            self.logger.info('Saving the last model ...')\n","            self.save_model(save_path + '_last')\n","            self.logger.info('Loading best model, Evaluating on Test data')\n","            self.load_model(save_path)\n","            test_results = self.evaluate('test', self.best_epoch)\n","        except Exception as e:\n","            self.logger.debug(\"%s____%s\\n\"\n","                              \"traceback.format_exc():____%s\" % (Exception, e, traceback.format_exc()))"]},{"cell_type":"markdown","metadata":{"id":"dsr1sSDh_bBa"},"source":["## FB15k-237"]},{"cell_type":"markdown","metadata":{"id":"9qFkjgD53nmU"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.564142Z","iopub.status.busy":"2023-08-29T11:31:27.563792Z","iopub.status.idle":"2023-08-29T11:31:27.578918Z","shell.execute_reply":"2023-08-29T11:31:27.577784Z","shell.execute_reply.started":"2023-08-29T11:31:27.564089Z"},"id":"dTKD50vHzxn8","trusted":true},"outputs":[],"source":["class Hyperparameters():\n","\n","  def __init__(self):\n","    self.name = 'FB15k-237_T5_last'          # Set run name for saving/restoring models (str)\n","    # self.name = self.name + '_' + time.strftime('%d_%m_%Y') + '_' + time.strftime('%H:%M:%S')\n","    self.dataset = 'FB15k-237'     # Dataset to use (str)\n","    self.model = 'ragat'           # Model name (str)\n","    self.score_func = 'interacte'  # Score Function for Link prediction (str)\n","    self.opn = 'cross'             # Composition Operation to be used in RAGAT (str)\n","\n","    self.batch_size = 1024         # Batch size (int)\n","    self.test_batch_size = 1024    # Batch size of valid and test data (int)\n","    self.gamma = 40.0              # Margin (float)\n","    self.gpu = '0'                 # Set GPU Ids : Eg: For CPU = -1, For Single GPU = 0 (str)\n","    self.max_epochs = 150        # Number of epochs (int)\n","    self.l2 = 0.0                  # L2 Regularization for Optimizer (float)\n","    self.lr = 0.001               # Starting Learning Rate (float)\n","    self.lbl_smooth = 0.1          # Label Smoothing (float)\n","    self.num_workers = 2          # Number of processes to construct batches (int)\n","    self.seed = 41504              # Seed for randomization (int)\n","\n","    self.restore = False        # Restore from the previously saved model (True or False)\n","    self.bias = True               # Whether to use bias in the model (True or False)\n","\n","    self.init_dim = 100            # Initial dimension size for entities and relations (int)\n","    self.gcn_dim = 200             # Number of hidden units in GCN (int)\n","    self.embed_dim = 200           # Embedding dimension to give as input to score function (int)\n","    self.gcn_layer = 1             # Number of GCN Layers to use (int)\n","    self.dropout = 0.4             # Dropout to use in GCN Layer (float)\n","    self.hid_drop = 0.3            # Dropout after GCN\n","\n","    # ConvE specific hyperparameters\n","    self.hid_drop2 = 0.3           # ConvE: Hidden dropout (float)\n","    self.feat_drop = 0.3           # ConvE: Feature Dropout (float)\n","    self.k_w = 16                  # ConvE: k_w (int)\n","    self.k_h = 16                  # ConvE: k_h (int)\n","    self.num_filt = 200            # ConvE: Number of filters in convolution (int)\n","    self.ker_sz = 7                # ConvE: Kernel size to use (int)\n","\n","    self.log_dir = log_dir         # Log directory (str)\n","    self.config_dir = './config/'  # Config directory (str)\n","\n","    # InteractE hyperparameters\n","    self.neg_num = 1000            # Number of negative samples to use for loss calculation (int)\n","    self.strategy = 'one_to_n'     # Training strategy to use (str)\n","    self.form = 'plain'            # The reshaping form to use (str)\n","    self.ik_w = 10                 # Width of the reshaped matrix (int)\n","    self.ik_h = 20                 # Height of the reshaped matrix (int)\n","    self.inum_filt = 200           # Number of filters in convolution (int)\n","    self.iker_sz = 9               # Kernel size to use (int)\n","    self.iperm = 1                 # Number of Feature rearrangement to use (int)\n","    self.iinp_drop = 0.3           # Dropout for Input layer (float)\n","    self.ifeat_drop = 0.4          # Dropout for Feature (float)\n","    self.ihid_drop = 0.3           # Dropout for Hidden layer (float)\n","    self.att = True                # Whether to use attention layer (True or False)\n","    self.head_num = 2              # Number of attention head (int)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.581087Z","iopub.status.busy":"2023-08-29T11:31:27.580383Z","iopub.status.idle":"2023-08-29T11:31:27.640963Z","shell.execute_reply":"2023-08-29T11:31:27.640173Z","shell.execute_reply.started":"2023-08-29T11:31:27.581048Z"},"id":"dh3OA9-G5Wmj","trusted":true},"outputs":[],"source":["args = Hyperparameters()\n","\n","np.set_printoptions(precision=4)\n","set_gpu(args.gpu)\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed_all(args.seed)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T11:31:27.642863Z","iopub.status.busy":"2023-08-29T11:31:27.642236Z","iopub.status.idle":"2023-08-29T11:31:27.834747Z","shell.execute_reply":"2023-08-29T11:31:27.833409Z","shell.execute_reply.started":"2023-08-29T11:31:27.642826Z"},"id":"qb9WDfvgCiPr","trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-08-29T11:31:27.839408Z","iopub.status.busy":"2023-08-29T11:31:27.838650Z","iopub.status.idle":"2023-08-29T22:22:51.077633Z","shell.execute_reply":"2023-08-29T22:22:51.076410Z","shell.execute_reply.started":"2023-08-29T11:31:27.839359Z"},"id":"yzLnAFjC3mgc","outputId":"63c27830-171f-4741-cb6e-d080b83010e7","trusted":true},"outputs":[],"source":["model = Runner(args)\n","model.fit()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## WN18RR"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Hyperparameters():\n","\n","  def __init__(self):\n","    self.name = 'RAGATv2_WN18RR_T2_E600'          # Set run name for saving/restoring models (str)\n","    #self.name = self.name + '_' + time.strftime('%d_%m_%Y') + '_' + time.strftime('%H:%M:%S')\n","    self.dataset = 'WN18RR'     # Dataset to use (str)\n","    self.model = 'ragat'           # Model name (str)\n","    self.score_func = 'interacte'  # Score Function for Link prediction (str)\n","    self.opn = 'cross'             # Composition Operation to be used in RAGAT (str)\n","\n","    self.batch_size = 256          # Batch size (int)\n","    self.test_batch_size = 256     # Batch size of valid and test data (int)\n","    self.gamma = 30.0              # Margin (float)\n","    self.gpu = '0'                 # Set GPU Ids : Eg: For CPU = -1, For Single GPU = 0 (str)\n","    self.max_epochs = 150          # Number of epochs (int)\n","    self.l2 = 0.0                  # L2 Regularization for Optimizer (float)\n","    self.lr = 0.001                # Starting Learning Rate (float)\n","    self.lbl_smooth = 0.1          # Label Smoothing (float)\n","    self.num_workers = 2           # Number of processes to construct batches (int)\n","    self.seed = 41504              # Seed for randomization (int)\n","\n","    self.restore = True            # Restore from the previously saved model (True or False)\n","    self.bias = True               # Whether to use bias in the model (True or False)\n","\n","    self.init_dim = 100            # Initial dimension size for entities and relations (int)\n","    self.gcn_dim = 200             # Number of hidden units in GCN (int)\n","    self.embed_dim = 200           # Embedding dimension to give as input to score function (int)\n","    self.gcn_layer = 1             # Number of GCN Layers to use (int)\n","    self.dropout = 0.7             # Dropout to use in GCN Layer (float)\n","    self.hid_drop = 0.4            # Dropout after GCN\n","\n","    # ConvE specific hyperparameters\n","    self.hid_drop2 = 0.3           # ConvE: Hidden dropout (float)\n","    self.feat_drop = 0.3           # ConvE: Feature Dropout (float)\n","    self.k_w = 10                  # ConvE: k_w (int)\n","    self.k_h = 20                  # ConvE: k_h (int)\n","    self.num_filt = 200            # ConvE: Number of filters in convolution (int)\n","    self.ker_sz = 7                # ConvE: Kernel size to use (int)\n","\n","    self.log_dir = log_dir         # Log directory (str)\n","    self.config_dir = './config/'  # Config directory (str)\n","\n","    # InteractE hyperparameters\n","    self.neg_num = 2000            # Number of negative samples to use for loss calculation (int)\n","    self.strategy = 'one_to_n'     # Training strategy to use (str)\n","    self.form = 'plain'            # The reshaping form to use (str)\n","    self.ik_w = 10                 # Width of the reshaped matrix (int)\n","    self.ik_h = 20                 # Height of the reshaped matrix (int)\n","    self.inum_filt = 200           # Number of filters in convolution (int)\n","    self.iker_sz = 11              # Kernel size to use (int)\n","    self.iperm = 4                 # Number of Feature rearrangement to use (int)\n","    self.iinp_drop = 0.3           # Dropout for Input layer (float)\n","    self.ifeat_drop = 0.2          # Dropout for Feature (float)\n","    self.ihid_drop = 0.3           # Dropout for Hidden layer (float)\n","    self.att = True                # Whether to use attention layer (True or False)\n","    self.head_num = 2              # Number of attention head (int)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
